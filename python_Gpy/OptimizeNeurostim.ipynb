{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full implementation of GP-BO optimization of neurostimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@file OptimizeNeurostim.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@authors Rose Guay-Hottin https://github.com/RoseGH20  \n",
    "         Marco Bonizzato https://github.com/mbonizzato  \n",
    "@version 1.0 / June 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays algorithmic performance on provided datasets\n",
    "for all values of a selected hyperparameter.\n",
    "\n",
    "Hyperparameter selection is crucial for GP-BO applications. We recommend\n",
    "running this code on own existing or surrogate data to tune at least the\n",
    "UCB acquisition function hyperparameter \"k\" (kappa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import time\n",
    "from datetime import date\n",
    "import GPy \n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The procedure can take approximately 3.0 to 5.0 hours on a standard workstation (Intel i7-8700 @ 3.2GHz)\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset= 'rat_data'\n",
    "dataset='rat' # selected dataset\n",
    "which_opt= 'kappa' # hyperparameter to optimize\n",
    "nRep=30 # number of repetitions\n",
    "get_running_time(dataset,nRep) # Provide a rough estimation of running time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of kappa to be tested: [ 1.   1.5  2.   2.3  2.6  2.9  3.2  3.5  3.8  4.1  5.   6.   7.   8.\n",
      "  9.  10. ]\n"
     ]
    }
   ],
   "source": [
    "mKernel=5 #Matern kernel order\n",
    "\n",
    "# rho (high, low) is the kernel geometrical hyperparameter (lengthscales)\n",
    "# kappa is the UCB acquisition function hyperparameter\n",
    "# nrnd is the number of random queries performed to initialize the GP-BO\n",
    "# noisemax is the maximum value for the noise hyperparameter\n",
    "\n",
    "if dataset=='nhp':\n",
    "    noise_min= 0.009 #Non-zero to avoid numerical instability\n",
    "    kappa=4.0 \n",
    "    rho_high=3.0 \n",
    "    rho_low=0.1\n",
    "    nrnd=1 #has to be >= 1\n",
    "    noise_max=0.011\n",
    "    n_subject=4\n",
    "    n_Chan=96\n",
    "    # In this version, datasets are not loaded synchronously,\n",
    "    # so we here define the total number of EMG and the max number per subject to expect\n",
    "    tot_emgs=22\n",
    "    max_emgs=8\n",
    "    \n",
    "elif dataset=='rat':\n",
    "    noise_min=0.0001\n",
    "    kappa=3.0\n",
    "    rho_high=5 \n",
    "    rho_low=0.02\n",
    "    nrnd=1 #has to be >= 1\n",
    "    noise_max=0.05\n",
    "    n_subject=6\n",
    "    n_Chan=32\n",
    "    # In this version, datasets are not loaded synchronously,\n",
    "    # so we here define the total number of EMG and the max number per subject to expect\n",
    "    tot_emgs=40\n",
    "    max_emgs=8\n",
    "    \n",
    "this_opt= param_grid(which_opt, dataset) # A selection of values to be tested for the selected hyperparameter\n",
    "\n",
    "# prepare results storage\n",
    "hyperparams = np.zeros((n_subject,max_emgs,len(this_opt),nRep, n_Chan,4)) # hyperparameters\n",
    "Stored_MaxSeenResp = np.zeros((n_subject,max_emgs,len(this_opt),nRep, n_Chan)) # maximum recorded response\n",
    "Stored_perf_explore = np.zeros((n_subject,max_emgs, len(this_opt), nRep, n_Chan)) # exploration score\n",
    "Stored_perf_exploit = np.zeros((n_subject,max_emgs, len(this_opt), nRep, n_Chan)) # exploitation score\n",
    "Stored_P_test= np.zeros((n_subject,max_emgs ,len(this_opt),nRep, n_Chan, 2)) # points tested and response\n",
    "Stored_MappingAccuracyRSQ= np.zeros((n_subject,max_emgs, len(this_opt), nRep)) # R-squared of mapping accuracy\n",
    "#Stored_YMU= np.zeros((n_subject,max_emgs,len(this_opt),nRep, n_Chan,n_Chan)) # predicted map, as average of GP fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# timing estimation utilities\n",
    "startTime = time.time()\n",
    "count_perf=0\n",
    "tot_perf=tot_emgs*len(this_opt)  \n",
    "\n",
    "for m_i in range(n_subject): # for each subject\n",
    "    \n",
    "    subject=load_matlab_data(path_to_dataset,dataset,m_i) # due to memory limitations, each subject is loaded sequentially\n",
    "    # during the optimization\n",
    "    \n",
    "    for k_i in range(len(this_opt)): # for each hyperparameter value\n",
    "        if which_opt=='nrnd':\n",
    "            nrnd= this_opt[k_i]\n",
    "        elif which_opt=='rho_low':\n",
    "            rho_low= this_opt[k_i]\n",
    "        elif which_opt=='rho_high':\n",
    "            rho_high= this_opt[k_i]\n",
    "        elif which_opt=='noise_min':\n",
    "            noise_min= this_opt[k_i]\n",
    "            noise_max= noise_min*1.1\n",
    "        elif which_opt=='noise_max':\n",
    "            noise_max= this_opt[k_i]\n",
    "            noise_min=0.0001\n",
    "        elif which_opt=='kappa':\n",
    "            kappa= this_opt[k_i]\n",
    "            \n",
    "        for e_i in range(len(subject['emgs'])): # for each muscle of the given subject\n",
    "         \n",
    "            # display remaining time information    \n",
    "            print([m_i, k_i, e_i])\n",
    "            print(str(count_perf/tot_perf*100)+ ' % completed')\n",
    "            \n",
    "            if count_perf>0:\n",
    "                t=time.time() - startTime\n",
    "                hs=np.floor((t/count_perf)*(tot_perf-count_perf)/60/60)\n",
    "                mins=np.floor((t/count_perf)*(tot_perf-count_perf)/60-hs*60)\n",
    "                print('Estimated remaining time: '+ str(hs)+ ' hours, '+ str(mins)+ ' minutes.')\n",
    "\n",
    "            # \"Ground truth\" map\n",
    "            MPm= subject['sorted_respMean'][:,e_i]\n",
    "            # Best known channel\n",
    "            mMPm= np.max(MPm)\n",
    "        \n",
    "            # Create the kernel\n",
    "            # Put a  prior on the two lengthscale hyperparameters and the variance\n",
    "            matk = GPy.kern.Matern52(input_dim=2,variance=1.0, lengthscale=[1.0, 1.0], ARD=True, name='Mat52') \n",
    "            matk.variance.set_prior(GPy.priors.Uniform(0.01**2,100**2), warning=False)\n",
    "            matk.lengthscale.set_prior(GPy.priors.Uniform(rho_low, rho_high), warning=False)\n",
    "            \n",
    "            # Then run the sequential optimization\n",
    "            DimSearchSpace = subject['nChan']\n",
    "            MaxQueries = DimSearchSpace\n",
    "            perf_explore= np.zeros((nRep, DimSearchSpace))\n",
    "            perf_exploit= np.zeros((nRep, DimSearchSpace))\n",
    "            MappingAccuracyRSQ= np.zeros((nRep))\n",
    "            P_test =  np.zeros((nRep, DimSearchSpace, 2)) #storing all queries\n",
    "            \n",
    "            for rep_i in range(nRep): # for each repetition\n",
    "                # maximum response obtained in this round, used to normalize all responses between zero and one.                \n",
    "                MaxSeenResp=0 \n",
    "                q=0 # query number                                \n",
    "                hyp=[1.0, 1.0, 1.0, 1.0]  # initialize kernel hyperparameters               \n",
    "                order_this= np.random.permutation(DimSearchSpace) # random permutation of each entry of the search space\n",
    "                P_max=[] \n",
    "            \n",
    "                while q < MaxQueries:\n",
    "                    # We will sample the search space randomly for exactly nrnd queries\n",
    "                    if q>=nrnd:\n",
    "                        # Find next point (max of acquisition function)\n",
    "                        AcquisitionMap = ymu + kappa*np.nan_to_num(np.sqrt(ys2)) # UCB acquisition\n",
    "                        NextQuery= np.where(AcquisitionMap.reshape(len(AcquisitionMap))==np.max(AcquisitionMap.reshape(len(AcquisitionMap))))\n",
    "                        # select next query\n",
    "                        if len(NextQuery) > 1:\n",
    "                            NextQuery = NextQuery[np.random.randint(len(NextQuery))]    \n",
    "                        else:   \n",
    "                            NextQuery = NextQuery[0]\n",
    "                        P_test[rep_i][q][0]= NextQuery[0]\n",
    "                    else:\n",
    "                        P_test[rep_i][q][0]= int(order_this[q]) \n",
    "                    query_elec = P_test[rep_i][q][0]\n",
    "                    \n",
    "                    # This offline optimization code randomly choses one\n",
    "                    # response among all responses stored in the\n",
    "                    # selected search space look-up table.\n",
    "                    valid_resp= subject['sorted_resp'][int(query_elec)][e_i][subject['sorted_isvalid'][int(query_elec)][e_i]!=0]\n",
    "                    r_i= np.random.randint(len(valid_resp)) \n",
    "                    test_respo= valid_resp[r_i]\n",
    "                    # done reading response\n",
    "                    P_test[rep_i][q][1]= test_respo\n",
    "                    # The first element of P_test is the selected search\n",
    "                    # space point, the second the resulting value\n",
    "                        \n",
    "                    if (test_respo > MaxSeenResp) or (MaxSeenResp==0):\n",
    "                        # updated maximum response obtained in this round\n",
    "                        MaxSeenResp=test_respo                           \n",
    "                        \n",
    "                    x= subject['ch2xy'][P_test[rep_i][:q+1,0].astype(int),:] # search space position\n",
    "                    y= P_test[rep_i][:q+1,1]/MaxSeenResp # test result \n",
    "                    y= y.reshape((len(y),1))\n",
    "                \n",
    "                    # Update the initial value of the parameters  \n",
    "                    matk.variance= hyp[2]\n",
    "                    matk.lengthscale[0]= hyp[0]\n",
    "                    matk.lengthscale[1]= hyp[1]\n",
    "                        \n",
    "                    # Initialization of the model and the constraint of the Gaussian noise \n",
    "                    if q==0:\n",
    "                        m=GPy.models.GPRegression(x,y, kernel= matk, normalizer=None, noise_var=hyp[3])\n",
    "                        m.Gaussian_noise.constrain_bounded(noise_min**2,noise_max**2, warning=False)\n",
    "                    else:\n",
    "                        m.set_XY(x,y)\n",
    "                        m.Gaussian_noise.variance[0]=hyp[3]\n",
    "                    \n",
    "                    # GP-BO optimization\n",
    "                    m.optimize(optimizer='scg', start= None, messages=False, max_iters=10, ipython_notebook=True,\n",
    "                               clear_after_finish=True)\n",
    "\n",
    "                    X_test= subject['ch2xy']\n",
    "                    ymu, ys2= m.predict(X_test, full_cov=False, Y_metadata=None, include_likelihood=True)\n",
    "                    \n",
    "                    # We only test for gp predictions at electrodes that\n",
    "                    # we had queried (presumable we only want to return an\n",
    "                    # electrode that we have already queried). \n",
    "                    Tested= np.unique(P_test[rep_i][:q+1,0].astype(int))\n",
    "                    MapPredictionTested=ymu[Tested]\n",
    "                    BestQuery= Tested[(MapPredictionTested==np.max(MapPredictionTested)).reshape(len(MapPredictionTested))]\n",
    "                    \n",
    "                    if len(BestQuery) > 1:\n",
    "                        BestQuery = np.array([BestQuery[np.random.randint(len(BestQuery))]])\n",
    "                    # Maximum response at time q           \n",
    "                    P_max.append(BestQuery[0])\n",
    "                    # store all info\n",
    "                    Stored_MaxSeenResp[m_i,e_i,k_i,rep_i,q] = MaxSeenResp\n",
    "                    hyp= [m.Mat52.lengthscale[0], m.Mat52.lengthscale[1], m.Mat52.variance[0], m.Gaussian_noise.variance[0]] \n",
    "                    hyperparams[m_i,e_i,k_i,rep_i,q,:] = hyp\n",
    "                    #Stored_YMU[m_i,e_i,k_i,rep_i,q,:]=ymu.reshape(len(ymu))\n",
    "                    q+=1\n",
    "                \n",
    "                # estimate current exploration performance: knowledge of best stimulation point\n",
    "                perf_explore[rep_i,:]=MPm[P_max].reshape((len(MPm[P_max])))/mMPm \n",
    "                # estimate current exploitation performance: knowledge of best stimulation point\n",
    "                perf_exploit[rep_i,:]= P_test[rep_i][:,0].astype(int) \n",
    "                # calculate model fitting of ground truth value map\n",
    "                mdl= np.corrcoef(MPm, ymu.reshape(ymu.shape[0]))[0,1]\n",
    "                MappingAccuracyRSQ[rep_i]=mdl**2\n",
    "                # store all tests\n",
    "                Stored_P_test[m_i,e_i,k_i,rep_i,:]=P_test[rep_i]\n",
    "            \n",
    "            # store all performance estimations\n",
    "            Stored_MappingAccuracyRSQ[m_i,e_i,k_i]=MappingAccuracyRSQ\n",
    "            Stored_perf_explore[m_i,e_i,k_i]=perf_explore\n",
    "            Stored_perf_exploit[m_i,e_i,k_i]= MPm[perf_exploit.astype(int)]/mMPm;\n",
    "            count_perf+=1\n",
    "            \n",
    "# Saving variables                        \n",
    "np.savez(dataset+'_'+which_opt+'_'+str(nRep)+'_'+date.today().strftime(\"%y%m%d\")+'.npz',\n",
    "         Stored_MaxSeenResp=Stored_MaxSeenResp, hyperparams=hyperparams, Stored_P_test=Stored_P_test,\n",
    "         Stored_perf_explore=Stored_perf_explore, Stored_perf_exploit=Stored_perf_exploit,\n",
    "         Stored_MappingAccuracyRSQ=Stored_MappingAccuracyRSQ, this_opt=this_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show performance graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data are displayed as mean +/- SEM\n",
    "plot_optim_results(Stored_perf_explore,Stored_perf_exploit,which_opt, this_opt, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
